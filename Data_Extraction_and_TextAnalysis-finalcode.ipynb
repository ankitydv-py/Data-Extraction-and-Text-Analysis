{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blackcoffer_task_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD4Ix4NZxlXg"
      },
      "source": [
        "### Objective of this assignment is to extract textual data from SEC / EDGAR financial reports and perform text analysis to compute different variables \n",
        "\n",
        "1.\tAll input variables in “cik_list.xlsx”\n",
        "2.\tpositive_score\n",
        "3.\tnegative_score\n",
        "4.\tpolarity_score\n",
        "5.\taverage_sentence_length\n",
        "6.\tpercentage_of_complex_words\n",
        "7.\tfog_index\n",
        "8.\tcomplex_word_count\n",
        "9.\tword_count\n",
        "10.\tuncertainty_score\n",
        "11.\tconstraining_score\n",
        "12.\tpositive_word_proportion\n",
        "13.\tnegative_word_proportion\n",
        "14.\tuncertainty_word_proportion\n",
        "15.\tconstraining_word_proportion\n",
        "16.\tconstraining_words_whole_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWAx8ZBBaxz"
      },
      "source": [
        "## Importing different libraries used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ec50sIPeBnd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "from urllib.request import Request, urlopen\n",
        "import re\n",
        "import requests"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-mvX3gPBUYt"
      },
      "source": [
        "## Importing all files from the drive used in the code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ewrVNtAzNik"
      },
      "source": [
        "#import cik_list excel file for inputs\n",
        "input_file_df = pd.read_excel(\"/content/drive/MyDrive/Doc/Blackcoffer_task/cik_list.xlsx\", dtype=object)\n",
        "\n",
        "#import another excel file for output file format\n",
        "output_file_df = pd.read_excel(\"/content/drive/MyDrive/Doc/Blackcoffer_task/Output Data Structure.xlsx\")\n",
        "\n",
        "\n",
        "#import sentimentalword file (positive and negative files)\n",
        "positive_df = pd.read_excel(\"/content/drive/MyDrive/Doc/Blackcoffer_task/SentimentWordLists.xlsx\", sheet_name=\"Positive\", header=None, dtype=object)\n",
        "negative_df = pd.read_excel(\"/content/drive/MyDrive/Doc/Blackcoffer_task/SentimentWordLists.xlsx\", sheet_name=\"Negative\", header=None, dtype=object)\n",
        "\n",
        "#uncertainity dictionary file\n",
        "uncertainity_df = pd.read_excel(\"/content/drive/MyDrive/Doc/Blackcoffer_task/uncertainty_dictionary.xlsx\", header=None)\n",
        "\n",
        "#constraining dictionary file\n",
        "constraining_df = pd.read_excel(\"/content/drive/MyDrive/Doc/Blackcoffer_task/constraining_dictionary.xlsx\", header=None)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54mD02G70752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca2d35e-f1aa-483f-ad2a-b5a54e52f314"
      },
      "source": [
        "input_file_df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 152 entries, 0 to 151\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype         \n",
            "---  ------    --------------  -----         \n",
            " 0   CIK       152 non-null    object        \n",
            " 1   CONAME    152 non-null    object        \n",
            " 2   FYRMO     152 non-null    object        \n",
            " 3   FDATE     152 non-null    datetime64[ns]\n",
            " 4   FORM      152 non-null    object        \n",
            " 5   SECFNAME  152 non-null    object        \n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 7.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxgNqJY1Cxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0c51c9-130d-4db3-d760-634ea2bff1be"
      },
      "source": [
        "input_file_df['SECFNAME']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       edgar/data/3662/0000950170-98-000413.txt\n",
              "1       edgar/data/3662/0000950170-98-001001.txt\n",
              "2       edgar/data/3662/0000950172-98-000783.txt\n",
              "3       edgar/data/3662/0000950170-98-002145.txt\n",
              "4       edgar/data/3662/0000950172-98-001203.txt\n",
              "                         ...                    \n",
              "147    edgar/data/12239/0001104659-07-024804.txt\n",
              "148    edgar/data/12239/0001104659-07-040463.txt\n",
              "149    edgar/data/12239/0001104659-07-041441.txt\n",
              "150    edgar/data/12239/0001104659-07-042333.txt\n",
              "151    edgar/data/12239/0001104659-07-062470.txt\n",
              "Name: SECFNAME, Length: 152, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj3jKjc23ZFc"
      },
      "source": [
        "### Add https://www.sec.gov/Archives/ to every cells of column SECFNAME of (cik_list.xlsx) as prefix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5rccqeE3c4V"
      },
      "source": [
        "# string to add as prefix\n",
        "prefix_toadd = \"https://www.sec.gov/Archives/\";\n",
        "\n",
        "#concate of two string urls\n",
        "input_file_df['SECFNAME'] = prefix_toadd + input_file_df['SECFNAME'];"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ArVYEfBf304X",
        "outputId": "8a2323e6-d781-4c36-c458-a1c7c1a4fb8b"
      },
      "source": [
        "#check the link again\n",
        "input_file_df['SECFNAME'][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy2mqCNu4Kk1",
        "outputId": "e284f20d-e65c-4042-eff0-a55208a34ab8"
      },
      "source": [
        "#check for null values in the input file\n",
        "input_file_df.isnull().values.any()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRy6qLNJ4rDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737e6880-18b2-448c-f283-2c5ff0e207e2"
      },
      "source": [
        "# check no of columns in the output file\n",
        "output_file_df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 0 entries\n",
            "Data columns (total 21 columns):\n",
            " #   Column                           Non-Null Count  Dtype \n",
            "---  ------                           --------------  ----- \n",
            " 0   CIK                              0 non-null      object\n",
            " 1   CONAME                           0 non-null      object\n",
            " 2   FYRMO                            0 non-null      object\n",
            " 3   FDATE                            0 non-null      object\n",
            " 4   FORM                             0 non-null      object\n",
            " 5   SECFNAME                         0 non-null      object\n",
            " 6   positive_score                   0 non-null      object\n",
            " 7   negative_score                   0 non-null      object\n",
            " 8   polarity_score                   0 non-null      object\n",
            " 9   average_sentence_length          0 non-null      object\n",
            " 10  percentage_of_complex_words      0 non-null      object\n",
            " 11  fog_index                        0 non-null      object\n",
            " 12  complex_word_count               0 non-null      object\n",
            " 13  word_count                       0 non-null      object\n",
            " 14  uncertainty_score                0 non-null      object\n",
            " 15  constraining_score               0 non-null      object\n",
            " 16  positive_word_proportion         0 non-null      object\n",
            " 17  negative_word_proportion         0 non-null      object\n",
            " 18  uncertainty_word_proportion      0 non-null      object\n",
            " 19  constraining_word_proportion     0 non-null      object\n",
            " 20  constraining_words_whole_report  0 non-null      object\n",
            "dtypes: object(21)\n",
            "memory usage: 0.0+ bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-sw4EMV4zUP"
      },
      "source": [
        "# drop the columns matches to input file from out file for smooth joining of two tables\n",
        "output_df = output_file_df.drop(['CIK','CONAME','FYRMO','FDATE','FORM','SECFNAME'],axis = 'columns')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFKtUBbC5DSN"
      },
      "source": [
        "# join two tables to create a final table\n",
        "final_file_df = input_file_df.join(output_df)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SReMccs05PrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953489ba-e85b-4183-db4e-29c5989eea83"
      },
      "source": [
        "# final file columns name\n",
        "final_file_df.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 152 entries, 0 to 151\n",
            "Data columns (total 21 columns):\n",
            " #   Column                           Non-Null Count  Dtype         \n",
            "---  ------                           --------------  -----         \n",
            " 0   CIK                              152 non-null    object        \n",
            " 1   CONAME                           152 non-null    object        \n",
            " 2   FYRMO                            152 non-null    object        \n",
            " 3   FDATE                            152 non-null    datetime64[ns]\n",
            " 4   FORM                             152 non-null    object        \n",
            " 5   SECFNAME                         152 non-null    object        \n",
            " 6   positive_score                   0 non-null      object        \n",
            " 7   negative_score                   0 non-null      object        \n",
            " 8   polarity_score                   0 non-null      object        \n",
            " 9   average_sentence_length          0 non-null      object        \n",
            " 10  percentage_of_complex_words      0 non-null      object        \n",
            " 11  fog_index                        0 non-null      object        \n",
            " 12  complex_word_count               0 non-null      object        \n",
            " 13  word_count                       0 non-null      object        \n",
            " 14  uncertainty_score                0 non-null      object        \n",
            " 15  constraining_score               0 non-null      object        \n",
            " 16  positive_word_proportion         0 non-null      object        \n",
            " 17  negative_word_proportion         0 non-null      object        \n",
            " 18  uncertainty_word_proportion      0 non-null      object        \n",
            " 19  constraining_word_proportion     0 non-null      object        \n",
            " 20  constraining_words_whole_report  0 non-null      object        \n",
            "dtypes: datetime64[ns](1), object(20)\n",
            "memory usage: 25.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDaoXe6rCBPU"
      },
      "source": [
        "## Dwonload ** Punkt ** Sentence Tokenizer. This divides a text into a list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0auvhbS5wJR",
        "outputId": "24c4a7f8-c4c3-4fa9-c822-765bddb4e45e"
      },
      "source": [
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edUsVvdWA1uZ"
      },
      "source": [
        "## Defining a bot function for the all operations and a loop for performing those operations to all rows "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jh0k95f51Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c60c12-97e9-408f-aef9-7b14a4e98ab5"
      },
      "source": [
        "i = 0\n",
        "def botfn(i):\n",
        "  try:\n",
        "    while (i < len(final_file_df['SECFNAME'])):\n",
        "      raw_html = urllib.request.urlopen(final_file_df['SECFNAME'][i])\n",
        "      raw_html = raw_html.read()\n",
        "      article_html = bs.BeautifulSoup(raw_html,'lxml')\n",
        "      article_paragraphs = article_html.find_all('p')\n",
        "      article_text = ''\n",
        "\n",
        "      for para in article_paragraphs:\n",
        "        article_text +=para.text\n",
        "\n",
        "      corpus = nltk.sent_tokenize(article_text)\n",
        "      for j in range (len(corpus)):\n",
        "        corpus[j] = corpus[j].lower()\n",
        "        corpus[j] = re.sub(r'\\W',' ',corpus[j])\n",
        "        corpus[j] = re.sub(r'\\s+',' ',corpus[j])\n",
        "        corpus[j] = re.sub(r'[0-9]', '', corpus[j])\n",
        "      # for total sentences use len(corpus)\n",
        "\n",
        "      from nltk.tokenize import word_tokenize\n",
        "\n",
        "      #Cleaning sentences by removing stopwords \n",
        "      # filtering sentences \n",
        "      corpus_filtered = []\n",
        "      for j in range(len(corpus)):\n",
        "        tokens = word_tokenize(corpus[j])\n",
        "        corpus_filtered.extend(tokens)\n",
        "\n",
        "      with open(\"/content/drive/MyDrive/Doc/Blackcoffer_task/StopWords_GenericLong.txt\", \"r\") as stopwordsfile:\n",
        "        stopwords = stopwordsfile.read().splitlines()\n",
        "      filtered_corpus_stpwrds = [word for word in corpus_filtered if not word in stopwords]\n",
        "\n",
        "      # Calculating Positive and Negative wordcore\n",
        "      # poitive words and entry in final_file_df table\n",
        "      positive_list = positive_df[0].tolist()\n",
        "      for j in range(len(positive_df)):\n",
        "        positive_list[j] = positive_list[j].lower()\n",
        "      positive_words = [word for word in filtered_corpus_stpwrds if word in positive_list]\n",
        "      positive_score = len(positive_words)\n",
        "      final_file_df['positive_score'][i] = positive_score\n",
        "\n",
        "      # negative words and entry in final_file_df table\n",
        "      negative_list = negative_df[0].tolist()\n",
        "      for j in range(len(negative_df)):\n",
        "        negative_list[j] = negative_list[j].lower()\n",
        "      negative_words = [word for word in filtered_corpus_stpwrds if word in negative_list]\n",
        "      negative_score = len(negative_words)\n",
        "      final_file_df['negative_score'][i] = negative_score\n",
        "\n",
        "      # Calculation of polarity score and entry in final_file_df table\n",
        "      Polarity_Score = (positive_score - negative_score)/((positive_score + negative_score) + 0.000001)\n",
        "\n",
        "      \n",
        "      if ( Polarity_Score < -0.5):                            # defining class on the basis of polarity score range\n",
        "        final_file_df['polarity_score'][i] = \"Most Negative\"\n",
        "      elif ( Polarity_Score >= -0.5 and Polarity_Score < 0):\n",
        "        final_file_df['polarity_score'][i] = \"Negative\"\n",
        "      elif ( Polarity_Score == 0):\n",
        "        final_file_df['polarity_score'][i] = \"Neutral\"\n",
        "      elif ( Polarity_Score > 0 and Polarity_Score < 0.5):\n",
        "        final_file_df['polarity_score'][i] = \"Positive\"\n",
        "      elif ( Polarity_Score >= 0.5 ):\n",
        "        final_file_df['polarity_score'][i] = \"Most Positive\"\n",
        "\n",
        "      # Calculating average_sentence_length and entry in final_file_df table\n",
        "      average_sentence_length = len(corpus_filtered)/len(corpus) # Exception - division by zero\n",
        "      final_file_df['average_sentence_length'][i] = average_sentence_length\n",
        "\n",
        "      # Calculating complex words and entry in final_file_df table\n",
        "      vowels = \"aeiou\"\n",
        "      complex_word_count = 0\n",
        "      for word in filtered_corpus_stpwrds:\n",
        "        if (word.endswith((\"es\",\"ed\",\"el\"))):\n",
        "          counter = 0\n",
        "        else:\n",
        "          counter = 0\n",
        "          for c in word:\n",
        "            if (c in vowels):\n",
        "              counter += 1\n",
        "        if (counter > 2):\n",
        "          complex_word_count += 1\n",
        "      \n",
        "      final_file_df['complex_word_count'][i] = complex_word_count\n",
        "      final_file_df['percentage_of_complex_words'][i] = complex_word_count / len(filtered_corpus_stpwrds)\n",
        "\n",
        "      # Calculating fog_index and entry in final_file_df table\n",
        "      \n",
        "      fog_index = 0.4 * (average_sentence_length + (complex_word_count/len(filtered_corpus_stpwrds))) # formula used : 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
        "      final_file_df['fog_index'][i] = fog_index\n",
        "\n",
        "      # Calculating wordcount and entry in final_file_df table\n",
        "      wordcount = len(corpus_filtered)\n",
        "      final_file_df['word_count'][i] = wordcount\n",
        "      \n",
        "      # Calculating uncertainty_score and entry in final_file_df table\n",
        "      uncertainity_list = uncertainity_df[0].tolist()\n",
        "      for j in range(len(uncertainity_list)):\n",
        "        uncertainity_list[j] = uncertainity_list[j].lower()\n",
        "      uncertainity_words = [word for word in filtered_corpus_stpwrds if word in uncertainity_list]\n",
        "      uncertainity_score = len(uncertainity_words)\n",
        "      final_file_df['uncertainty_score'][i] = uncertainity_score\n",
        "\n",
        "      # Calculating constraining_score and entry in final_file_df table\n",
        "      constraining_list = constraining_df[0].tolist()\n",
        "      for j in range(len(constraining_list)):\n",
        "        constraining_list[j] = constraining_list[j].lower()\n",
        "      constraining_words = [word for word in filtered_corpus_stpwrds if word in constraining_list]\n",
        "      constraining_score = len(constraining_words)\n",
        "      final_file_df['constraining_score'][i] = constraining_score\n",
        "\n",
        "      # Calculating positive_word_proportion and entry in final_file_df table\n",
        "      positive_word_proportion = positive_score/wordcount\n",
        "      final_file_df['positive_word_proportion'][i] = positive_word_proportion\n",
        "      \n",
        "      # Calculating negative_word_proportion and entry in final_file_df table\n",
        "      negative_word_proportion = negative_score/wordcount\n",
        "      final_file_df['negative_word_proportion'][i] = negative_word_proportion\n",
        "      \n",
        "      # Calculating uncertainty_word_proportion and entry in final_file_df table\n",
        "      uncertainty_word_proportion = uncertainity_score/wordcount\n",
        "      final_file_df['uncertainty_word_proportion'][i] = uncertainty_word_proportion\n",
        "      \n",
        "      # Calculating constraining_word_proportion and entry in final_file_df table\n",
        "      constraining_word_proportion = constraining_score/wordcount\n",
        "      final_file_df['constraining_word_proportion'][i] = constraining_word_proportion\n",
        "      \n",
        "      # Calculating constraining_words_whole_report and entry in final_file_df table\n",
        "      constraining_words_whole = [word for word in corpus_filtered if word in constraining_list]\n",
        "      constraining_score_whole_report = len(constraining_words_whole)\n",
        "      final_file_df['constraining_words_whole_report'][i] = constraining_score_whole_report      \n",
        "      \n",
        "      i = i + 1\n",
        "\n",
        "  except urllib.error.HTTPError as exception:\n",
        "    botfn(i)\n",
        "\n",
        "  except ZeroDivisionError as exception:\n",
        "    final_file_df['positive_score'][i]= 0\n",
        "    final_file_df['negative_score'][i]= 0\n",
        "    final_file_df['polarity_score'][i]= 0\n",
        "    final_file_df['average_sentence_length'][i]= 0\n",
        "    final_file_df['word_count'][i]= 0\n",
        "    final_file_df['uncertainty_score'][i]= 0\n",
        "    final_file_df['constraining_score'][i]= 0\n",
        "    final_file_df['positive_word_proportion'][i]= 0\n",
        "    final_file_df['positive_word_proportion'][i]= 0\n",
        "    final_file_df['negative_word_proportion'][i]= 0\n",
        "    final_file_df['uncertainty_word_proportion'][i]= 0\n",
        "    final_file_df['constraining_word_proportion'][i]= 0\n",
        "    final_file_df['constraining_word_proportion'][i]= 0\n",
        "    final_file_df['complex_word_count']=0\n",
        "    final_file_df['percentage_of_complex_words']= 0\n",
        "    final_file_df['fog_index']= 0\n",
        "    i += 1\n",
        "    botfn(i)\n",
        "botfn(i)\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:115: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:142: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:143: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:144: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:145: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:147: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:148: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:150: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:151: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:152: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eAQEQFAU2Q"
      },
      "source": [
        "## Creating a csv file of the final_file_df and save to drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMiL8pe3yHpn"
      },
      "source": [
        "with open('/content/drive/MyDrive/Doc/Blackcoffer_task/Blackcoffer_Submission_File.csv', 'w') as f:\n",
        "  final_file_df.to_csv(f)"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}